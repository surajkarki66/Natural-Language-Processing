{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LOAD THE TRAINING TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('./data/train.csv')\n",
    "test_data_sub=pd.read_csv('./data/test.csv')\n",
    "\n",
    "reviews=train_data['review']\n",
    "labels=train_data['sentiment'].values\n",
    "\n",
    "input_test=test_data_sub['review']\n",
    "y_test=list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TEXT PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "appos = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_formatting(reviews):\n",
    "    all_reviews=list()\n",
    "    for text in reviews:\n",
    "        lower_case = text.lower()\n",
    "        words = lower_case.split()\n",
    "        reformed = [appos[word] if word in appos else word for word in words]\n",
    "        reformed_test=list()\n",
    "        for word in reformed:\n",
    "            if word not in stop_words:\n",
    "                reformed_test.append(word)\n",
    "        reformed = \" \".join(reformed_test) \n",
    "        punct_text = \"\".join([ch for ch in reformed if ch not in punctuation])\n",
    "        all_reviews.append(punct_text)\n",
    "    all_text = \" \".join(all_reviews)\n",
    "    all_words = all_text.split()\n",
    "    return all_reviews, all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews, all_words = review_formatting(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['done', 'lot', 'international', 'travel', 'business', 'tourist', 'types', 'assure', 'best', 'advice', 'also', 'oldest', 'always', 'drink', 'wine', 'country', 'movie', 'archangel', 'michael', 'comes']\n"
     ]
    }
   ],
   "source": [
    "print(all_words[0:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['done lot international travel business tourist types assure best advice also oldest always drink wine country movie archangel michael comes earth business wraps quickly decides hang around little touring boy drink wine countrybr br could man drunk forever liquor love fights br br hed lief rise mornings lief lie nightsbr br these things cannot heaven enjoys he is here course turns couple jobs tackle and less direct first one successful final scene little schmaltzy also wonderful jean stapleton gets dance john travolta']\n"
     ]
    }
   ],
   "source": [
    "print(all_reviews[0:1]) # single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all the words using Counter Method\n",
    "all_reviews, all_words=review_formatting(reviews)\n",
    "count_words = Counter(all_words)\n",
    "total_words=len(all_words)\n",
    "sorted_words=count_words.most_common(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to convert words to Integers based on the number of occurrence of the word\n",
    "\n",
    "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}\n",
    "#print(vocab_to_int)\n",
    "print(vocab_to_int['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode review in to list of Integer by using above dictionary\n",
    "def encode_reviews(reviews):\n",
    "    \"\"\"\n",
    "    encode_reviews function will encodes review in to array of numbers\n",
    "    \"\"\"\n",
    "    all_reviews=list()\n",
    "    for text in reviews:\n",
    "        text = text.lower()\n",
    "        text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "        all_reviews.append(text)\n",
    "    encoded_reviews=list()\n",
    "    for review in all_reviews:\n",
    "        encoded_review=list()\n",
    "        for word in review.split():\n",
    "            if word not in vocab_to_int.keys():\n",
    "                encoded_review.append(0)\n",
    "            else:\n",
    "                encoded_review.append(vocab_to_int[word])\n",
    "        encoded_reviews.append(encoded_review)\n",
    "    return encoded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(encoded_reviews, sequence_length=250):\n",
    "    ''' \n",
    "    Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "    '''\n",
    "    features=np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
    "    \n",
    "    for i, review in enumerate(encoded_reviews):\n",
    "        review_len=len(review)\n",
    "        if (review_len<=sequence_length):\n",
    "            zeros=list(np.zeros(sequence_length-review_len))\n",
    "            new=zeros+review\n",
    "        else:\n",
    "            new=review[:sequence_length]\n",
    "        features[i,:]=np.array(new)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(reviews):\n",
    "    \"\"\"\n",
    "    This Function will tranform reviews in to model readable form\n",
    "    \"\"\"\n",
    "    formated_reviews, all_words = review_formatting(reviews)\n",
    "    encoded_reviews=encode_reviews(formated_reviews)\n",
    "    features=pad_sequences(encoded_reviews, 250)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze The Review Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_reviews=encode_reviews(reviews)\n",
    "review_len=[len(encoded_review) for encoded_review in encoded_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 53, 139, 230, 86, 609, 1816, 2006, 1912, 236, 924, 98, 324, 230, 4173, 449, 1912, 2073, 59, 6068, 46, 11, 43, 1872, 4, 22, 11, 6189, 119, 2763, 11, 3942, 609, 11, 608, 164, 54, 2, 11, 27083, 417, 172, 451, 657, 236, 924, 10979, 6, 351, 849, 98, 976, 451, 2987, 104, 449, 230, 42, 13640, 357, 67, 103, 2763, 11, 3942, 609, 11, 11683, 1, 21, 60, 574, 2068, 1416, 429, 11455, 41, 98, 1747, 1, 1, 31405, 43646, 2042, 351, 609, 24040, 98, 43646, 2621, 875, 609, 38236, 1, 2764, 64, 96, 46, 1511, 25, 164, 2021, 257, 103, 4190, 196, 970, 3843, 215, 609, 170, 6, 422, 242, 103, 285, 230, 272, 609, 684, 2718, 451, 8404, 98, 359, 103, 4, 258, 1530, 698, 196, 9953, 103, 121, 698, 11, 27, 7, 103, 4, 1621, 324, 1048, 11, 368, 58, 4, 230, 42, 14030, 231, 6, 4, 22, 298, 1748, 15217, 120, 451, 780, 429, 220, 5509]\n",
      "\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print(encoded_reviews[0])\n",
    "print()\n",
    "print(len(encoded_reviews[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAQNklEQVR4nO3df6jd9X3H8edrSSdia1EzLyEJS7rmj0Vltl4yR0e5Q6ip/UMLFVJkZkzIEMtayP6I6x8tjIAOrCCbshTFKF2t9AcKnVsl7aEIVhuLrUaXeVuzmiYYnNJ6hTpj3/vjfC473tyc3HPvzT335jwfcDjf8/5+P+d8z5uT+8r38/3ec1NVSJL0e8PeAUnS8mAgSJIAA0GS1BgIkiTAQJAkNauHvQPztWbNmtq4cePA49566y3OO++8xd+hs4T96c/+9Gd/+lsO/XnmmWdeq6o/mG3dig2EjRs3cuDAgYHHdTodJiYmFn+HzhL2pz/705/96W859CfJf59qnVNGkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJGAF/6byQmzc/d2hvfbh2z41tNeWpH48QpAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpOW0gJNmQ5AdJXkxyMMnnW/3CJI8neandX9Az5tYkk0kOJbm6p35FkufauruSpNXPSfKNVn8qycbFf6uSpH7mcoRwAthVVX8MXAnckmQLsBvYX1Wbgf3tMW3dduASYBtwd5JV7bnuAXYCm9ttW6vfBLxRVR8G7gRuX4T3JkkawGkDoaqOVdVP2vKbwIvAOuBaYF/bbB9wXVu+Fnioqt6uqpeBSWBrkrXA+VX1ZFUV8MCMMdPP9U3gqumjB0nS0lg9yMZtKucjwFPAWFUdg25oJLm4bbYO+FHPsCOt9k5bnlmfHvNKe64TSX4NXAS8NuP1d9I9wmBsbIxOpzPI7gMwNTXFrsveHXjcYpnPPi+lqampZb+Pw2R/+rM//S33/sw5EJK8H/gW8IWq+k2f/8DPtqL61PuNeW+hai+wF2B8fLwmJiZOs9cn63Q63PHEWwOPWyyHb5gY2mvPRafTYT59HRX2pz/7099y78+crjJK8j66YfC1qvp2K7/apoFo98db/QiwoWf4euBoq6+fpf6eMUlWAx8EXh/0zUiS5m8uVxkFuBd4saq+0rPqUWBHW94BPNJT396uHNpE9+Tx02166c0kV7bnvHHGmOnn+gzw/XaeQZK0ROYyZfQx4C+B55I822p/D9wGPJzkJuCXwPUAVXUwycPAC3SvULqlqqYn7W8G7gfOBR5rN+gGzoNJJukeGWxf4PuSJA3otIFQVU8w+xw/wFWnGLMH2DNL/QBw6Sz139ICRZI0HP6msiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkoA5BEKS+5IcT/J8T+3LSX6V5Nl2u6Zn3a1JJpMcSnJ1T/2KJM+1dXclSaufk+Qbrf5Uko2L+xYlSXMxlyOE+4Fts9TvrKrL2+3fAJJsAbYDl7QxdydZ1ba/B9gJbG636ee8CXijqj4M3AncPs/3IklagNMGQlX9EHh9js93LfBQVb1dVS8Dk8DWJGuB86vqyaoq4AHgup4x+9ryN4Grpo8eJElLZ/UCxn4uyY3AAWBXVb0BrAN+1LPNkVZ7py3PrNPuXwGoqhNJfg1cBLw28wWT7KR7lMHY2BidTmfgnZ6ammLXZe8OPG6xzGefl9LU1NSy38dhsj/92Z/+lnt/5hsI9wD/AFS7vwP4a2C2/9lXnzqnWffeYtVeYC/A+Ph4TUxMDLTT0P2BfMcTbw08brEcvmFiaK89F51Oh/n0dVTYn/7sT3/LvT/zusqoql6tqner6nfAV4GtbdURYEPPpuuBo62+fpb6e8YkWQ18kLlPUUmSFsm8AqGdE5j2aWD6CqRHge3tyqFNdE8eP11Vx4A3k1zZzg/cCDzSM2ZHW/4M8P12nkGStIROO2WU5OvABLAmyRHgS8BEksvpTu0cBv4GoKoOJnkYeAE4AdxSVdMT9jfTvWLpXOCxdgO4F3gwySTdI4Pti/HGJEmDOW0gVNVnZynf22f7PcCeWeoHgEtnqf8WuP50+yFJOrP8TWVJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBcwiEJPclOZ7k+Z7ahUkeT/JSu7+gZ92tSSaTHEpydU/9iiTPtXV3JUmrn5PkG63+VJKNi/sWJUlzMZcjhPuBbTNqu4H9VbUZ2N8ek2QLsB24pI25O8mqNuYeYCewud2mn/Mm4I2q+jBwJ3D7fN+MJGn+ThsIVfVD4PUZ5WuBfW15H3BdT/2hqnq7ql4GJoGtSdYC51fVk1VVwAMzxkw/1zeBq6aPHiRJS2e+5xDGquoYQLu/uNXXAa/0bHek1da15Zn194ypqhPAr4GL5rlfkqR5Wr3Izzfb/+yrT73fmJOfPNlJd9qJsbExOp3OwDs4NTXFrsveHXjcYpnPPi+lqampZb+Pw2R/+rM//S33/sw3EF5NsraqjrXpoOOtfgTY0LPdeuBoq6+fpd475kiS1cAHOXmKCoCq2gvsBRgfH6+JiYmBd7zT6XDHE28NPG6xHL5hYmivPRedTof59HVU2J/+7E9/y70/850yehTY0ZZ3AI/01Le3K4c20T15/HSbVnozyZXt/MCNM8ZMP9dngO+38wySpCV02iOEJF8HJoA1SY4AXwJuAx5OchPwS+B6gKo6mORh4AXgBHBLVU3Pz9xM94qlc4HH2g3gXuDBJJN0jwy2L8o7kyQN5LSBUFWfPcWqq06x/R5gzyz1A8Cls9R/SwsUSdLw+JvKkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkoDF/y4jncbG3d8dyusevu1TQ3ldSSuHRwiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVKzoEBIcjjJc0meTXKg1S5M8niSl9r9BT3b35pkMsmhJFf31K9ozzOZ5K4kWch+SZIGtxhHCH9RVZdX1Xh7vBvYX1Wbgf3tMUm2ANuBS4BtwN1JVrUx9wA7gc3ttm0R9kuSNIAzMWV0LbCvLe8DruupP1RVb1fVy8AksDXJWuD8qnqyqgp4oGeMJGmJrF7g+AK+l6SAf6mqvcBYVR0DqKpjSS5u264DftQz9kirvdOWZ9ZPkmQn3SMJxsbG6HQ6A+/w1NQUuy57d+BxK91cezU1NTWvvo4K+9Of/elvufdnoYHwsao62n7oP57kP/tsO9t5gepTP7nYDZy9AOPj4zUxMTHg7nZ/MN7xxFsDj1vpDt8wMaftOp0O8+nrqLA//dmf/pZ7fxY0ZVRVR9v9ceA7wFbg1TYNRLs/3jY/AmzoGb4eONrq62epS5KW0LwDIcl5ST4wvQx8AngeeBTY0TbbATzSlh8Ftic5J8kmuiePn27TS28mubJdXXRjzxhJ0hJZyJTRGPCddoXoauBfq+rfk/wYeDjJTcAvgesBqupgkoeBF4ATwC1VNT2ZfzNwP3Au8Fi7SZKW0LwDoap+AfzJLPX/Aa46xZg9wJ5Z6geAS+e7L5KkhfM3lSVJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpWchfTNMKsnH3d+e03a7LTvBXc9x2rg7f9qlFfT5JZ4ZHCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgD/HoKWwFz/FsNi8+8wSIPxCEGSBBgIkqTGQJAkAZ5D0FnsTJy7mMvfnPbchVaqZXOEkGRbkkNJJpPsHvb+SNKoWRaBkGQV8M/AJ4EtwGeTbBnuXknSaFkWgQBsBSar6hdV9b/AQ8C1Q94nSRopy+UcwjrglZ7HR4A/nblRkp3AzvZwKsmhebzWGuC1eYwbCX9rf/qaS39y+xLtzPLk56e/5dCfPzzViuUSCJmlVicVqvYCexf0QsmBqhpfyHOczexPf/anP/vT33Lvz3KZMjoCbOh5vB44OqR9kaSRtFwC4cfA5iSbkvw+sB14dMj7JEkjZVlMGVXViSSfA/4DWAXcV1UHz9DLLWjKaQTYn/7sT3/2p79l3Z9UnTRVL0kaQctlykiSNGQGgiQJGLFA8OsxIMnhJM8leTbJgVa7MMnjSV5q9xf0bH9r69ehJFcPb8/PjCT3JTme5Pme2sD9SHJF6+tkkruSzHYp9Ypziv58Ocmv2mfo2STX9Kwbtf5sSPKDJC8mOZjk862+Mj9DVTUSN7onq38OfAj4feCnwJZh79cQ+nAYWDOj9o/A7ra8G7i9LW9pfToH2NT6t2rY72GR+/Fx4KPA8wvpB/A08Gd0f6fmMeCTw35vZ7A/Xwb+bpZtR7E/a4GPtuUPAP/V+rAiP0OjdITg12Oc2rXAvra8D7iup/5QVb1dVS8Dk3T7eNaoqh8Cr88oD9SPJGuB86vqyer+y36gZ8yKdor+nMoo9udYVf2kLb8JvEj3mxdW5GdolAJhtq/HWDekfRmmAr6X5Jn2VSAAY1V1DLofcODiVh/Vng3aj3VteWb9bPa5JD9rU0rT0yEj3Z8kG4GPAE+xQj9DoxQIc/p6jBHwsar6KN1vlr0lycf7bGvP3utU/Ri1Pt0D/BFwOXAMuKPVR7Y/Sd4PfAv4QlX9pt+ms9SWTY9GKRD8egygqo62++PAd+hOAb3aDllp98fb5qPas0H7caQtz6yflarq1ap6t6p+B3yV/59GHMn+JHkf3TD4WlV9u5VX5GdolAJh5L8eI8l5ST4wvQx8Aniebh92tM12AI+05UeB7UnOSbIJ2Ez3xNfZbqB+tCmBN5Nc2a4MubFnzFln+gdd82m6nyEYwf6093Mv8GJVfaVn1cr8DA37LP1S3oBr6F4F8HPgi8PenyG8/w/RvcLhp8DB6R4AFwH7gZfa/YU9Y77Y+nWIs+TKkBk9+TrdaY936P4v7ab59AMYp/uD8efAP9G+BWCl307RnweB54Cf0f0Bt3aE+/PndKd2fgY8227XrNTPkF9dIUkCRmvKSJLUh4EgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1/wffq5SF1AHwVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    35000.000000\n",
       "mean       230.740571\n",
       "std        171.009115\n",
       "min          8.000000\n",
       "25%        126.000000\n",
       "50%        173.000000\n",
       "75%        281.000000\n",
       "max       2122.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(review_len).hist()\n",
    "plt.show()\n",
    "pd.Series(review_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
    "features=preprocess(reviews)\n",
    "train_x=features[:int(0.90*len(features))]\n",
    "train_y=labels[:int(0.90*len(features))]\n",
    "valid_x=features[int(0.90*len(features)):]\n",
    "valid_y=labels[int(0.90*len(features)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500 3500\n"
     ]
    }
   ],
   "source": [
    "print(len(train_y), len(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31500, 250)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,   139,    86,  1816,\n",
       "        2006,   924,  4173,  2073,  6068,    43,  1872,    22,  6189,\n",
       "         119,  2763,  3942,   608,     2, 27083,   417,   172,   657,\n",
       "         924, 10979,   849,   976,  2987,   104,    42, 13640,   357,\n",
       "        2763,  3942, 11683,     1,    21,    60,  2068,  1416, 11455,\n",
       "          41,  1747,     1,     1, 31405, 43646,  2042, 24040, 43646,\n",
       "        2621, 38236,     1,  2764,    96,    72,  2021,  4190,   103,\n",
       "           4,   215,   170,   422,   272,  2718,  8404,    98,   258,\n",
       "        1530,    27,     7,  1048,   368,    58,    42, 14030,    22,\n",
       "         298,  1748, 15217,   120,   780,   220,  5509])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensor Dataset\n",
    "\n",
    "train_data=TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data=TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f721657fbb0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "batch_size = 64\n",
    "\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([64, 250])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,  ...,   491,   730,   129],\n",
      "        [    0,     0,     0,  ...,  1115,  4945,  4945],\n",
      "        [    0,     0,     0,  ...,    36,   216,    31],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ..., 13493,   397,    47],\n",
      "        [    0,     0,     0,  ...,     1,     1, 27087],\n",
      "        [    0,     0,     0,  ...,   340,  2524,     2]])\n",
      "Sample label size:  torch.Size([64])\n",
      "Sample label: \n",
      " tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):    \n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size=output_size\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        #Embedding and LSTM layers\n",
    "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        #dropout layer\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "        \n",
    "        #Linear and sigmoid layer\n",
    "        self.fc1=nn.Linear(hidden_dim, 64)\n",
    "        self.fc2=nn.Linear(64, 16)\n",
    "        self.fc3=nn.Linear(16,output_size)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size=x.size()\n",
    "        \n",
    "        #Embedding and LSTM output\n",
    "        embedd=self.embedding(x)\n",
    "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
    "        \n",
    "        #stack up the lstm output(dimension reduction)(batch, sequence_len, emd_dim)\n",
    "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        #(batch x sequence_len, emb_dim)\n",
    "        #dropout and fully connected layers\n",
    "        out=self.dropout(lstm_out)\n",
    "        out=self.fc1(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc3(out)\n",
    "        sig_out=self.sigmoid(out)\n",
    "        \n",
    "        sig_out=sig_out.view(batch_size, -1)\n",
    "        sig_out=sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize Hidden STATE\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding): Embedding(148794, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Model(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 3 \n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(148794, 400)\n",
       "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-2b6cf1fd9baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()  \n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(input_test):\n",
    "    output_list=list()\n",
    "    batch_size=50   \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        test_review=preprocess(input_test)\n",
    "        for review in test_review:\n",
    "            # convert to tensor to pass into your model\n",
    "            feature_tensor = torch.from_numpy(review).view(1,-1)\n",
    "            if(train_on_gpu):\n",
    "                feature_tensor= feature_tensor.cuda()\n",
    "            batch_size = feature_tensor.size(0)\n",
    "            # initialize hidden state\n",
    "            h = net.init_hidden(batch_size)\n",
    "            # get the output from the model\n",
    "            output, h = net(feature_tensor, h)\n",
    "            pred = torch.round(output.squeeze()) \n",
    "            output_list.append(pred)\n",
    "        labels=[int(i.data.cpu().numpy()) for i in output_list]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-faf5b9c9cb72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-ef7b495ce631>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(input_test)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtest_review\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_review\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# convert to tensor to pass into your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-97282cd68506>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(reviews)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mFunction\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mtranform\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mreadable\u001b[0m \u001b[0mform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mformated_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_formatting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mencoded_reviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformated_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-5ebe275bb185>\u001b[0m in \u001b[0;36mreview_formatting\u001b[0;34m(reviews)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mreformed_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreformed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0mreformed_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mreformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreformed_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels=test_model(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
