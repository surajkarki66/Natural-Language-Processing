{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTb3M-dP3_Mz"
      },
      "source": [
        "## Simple Name Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wakoBZN74udS",
        "outputId": "7c77eeb5-2b27-4205-c27c-68a9faf33d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5peH_w-3_M0"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import utils \n",
        "import torch\n",
        "import logging\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from tqdm import trange\n",
        "from torch.autograd import Variable\n",
        "sys.path.append(\".\")"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuWVxBgg3_M_"
      },
      "source": [
        "### 1) Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmhI-eBZ3_NB"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, params):\n",
        "        \"\"\"\n",
        "        We define a recurrent network that predicts the NER tags for each token in the sentence. The components\n",
        "        required are:\n",
        "        - an embedding layer: this layer maps each index in range(params.vocab_size) to a params.embedding_dim vector\n",
        "        - lstm: applying the LSTM on the sequential input returns an output for each token in the sentence\n",
        "        - fc: a fully connected layer that converts the LSTM output for each token to a distribution over NER tags\n",
        "\n",
        "        Args:\n",
        "            params: (Params) contains vocab_size, embedding_dim, lstm_hidden_dim\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.embedding = nn.Embedding(params.vocab_size, params.embedding_dim)\n",
        "        self.lstm = nn.LSTM(params.embedding_dim,\n",
        "                            params.lstm_hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(params.lstm_hidden_dim, params.number_of_tags)\n",
        "        \n",
        "    def forward(self, s):\n",
        "        s = self.embedding(s)       # dim: batch_size x seq_len x embedding_dim\n",
        "        s, _ = self.lstm(s)\n",
        "        s = s.contiguous()          # required often before view\n",
        "        s = s.view(-1, s.shape[2])  # dim: batch_size*seq_len x lstm_hidden_dim\n",
        "        s = self.fc(s)\n",
        "        # softmax on all tokens (batch_size -> #sentences, seq_len -> #tokens_per_sentence, s-> all tokens)\n",
        "        return F.log_softmax(s, dim=1)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPkoIzSx3_NK"
      },
      "source": [
        "### 2) Loss Function\n",
        "Cross Entrophy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrBheE3H3_NL"
      },
      "source": [
        "\n",
        "def loss_fn(outputs, labels):\n",
        "    \"\"\"Compute the cross entropy loss over outputs from the model and labels for all tokens\n",
        "\n",
        "    Args:\n",
        "        outputs: (Variable) dimension batch_size*seq_len x num_tags - log softmax output of the model\n",
        "        labels: (Variable) dimension batch_size x seq_len where each element is either a label in [0, 1, ... num_tag-1],\n",
        "            or -1 in case it is a PADding token.\n",
        "    Returns:\n",
        "        loss: (Variable) cross entropy loss for all tokens in the batch\n",
        "    \"\"\"\n",
        "\n",
        "    # reshape to shape of batch_size*seq_len\n",
        "    labels = labels.view(-1)\n",
        "\n",
        "    # since padding tokens have label -1, we can generate a mask to exclude the loss from those terms\n",
        "    mask = (labels >= 0).float()\n",
        "\n",
        "    # indexing with negative values is not supported. Since PADded tokens have label -1, we convert them to a positive\n",
        "    # number. This does not affect training, since we ignore the PADded tokens with the mask.\n",
        "    labels = labels % outputs.shape[1]\n",
        "\n",
        "    num_tokens = int(torch.sum(mask))\n",
        "\n",
        "    # compute cross entropy loss for all tokens (except PADding tokens), by multiplying with mask\n",
        "    return -torch.sum(outputs[range(outputs.shape[0]), labels] * mask) / num_tokens\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEqdtzaa3_NS"
      },
      "source": [
        "### 3) Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDrlffSk3_NT"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    \"\"\"Compute accuracy for all tokens excluding Padding terms\"\"\"\n",
        "\n",
        "    labels = labels.ravel()  # flattened array\n",
        "    mask = (labels >= 0)\n",
        "    # np.argmax gives us the class predicted for each token by the model\n",
        "    outputs = np.argmax(outputs, axis=1)\n",
        "    return np.sum(outputs == labels) / float(np.sum(mask))\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAqRTPQ03_NW"
      },
      "source": [
        "# maintain all metrics required in this dictionary - these are used in the training and evaluation loops\n",
        "metrics = {\n",
        "    'accuracy': accuracy,\n",
        "    # add more metrics if required for each token type\n",
        "}"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se2e14w03_Na"
      },
      "source": [
        "### 4) Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wboYAVYS3_Nb"
      },
      "source": [
        "##### 1) Creating data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rik5BJ7z3_Nc"
      },
      "source": [
        "\n",
        "class DataLoader(object):\n",
        "    \"\"\"Stores dataset_params, vocabulary ad tags with their mapping to indices\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir, params):\n",
        "        \"\"\"Loads dataset_params, vocabulary and tags. Ensure you have already run build_vocab.py on data_dir\"\"\"\n",
        "\n",
        "        json_path = os.path.join(data_dir, 'dataset_params.json')\n",
        "        assert os.path.isfile(\n",
        "            json_path), \"No json file found at {}, run build_vocab.py\".format(json_path)\n",
        "        self.dataset_params = utils.Params(json_path)\n",
        "\n",
        "        # loading vocab\n",
        "        vocab_path = os.path.join(data_dir, 'words.txt')\n",
        "        self.vocab = {}\n",
        "        with open(vocab_path) as f:\n",
        "            # map words to their indices\n",
        "            for i, l in enumerate(f.read().splitlines()):\n",
        "                self.vocab[l] = i\n",
        "\n",
        "        # setting the indices for UNKnown words and PADding symbols\n",
        "        self.unk_ind = self.vocab[self.dataset_params.unk_word]\n",
        "        self.pad_ind = self.vocab[self.dataset_params.pad_word]\n",
        "\n",
        "        # loading tags\n",
        "        tags_path = os.path.join(data_dir, 'tags.txt')\n",
        "        self.tag_map = {}\n",
        "        with open(tags_path) as f:\n",
        "            for i, t in enumerate(f.read().splitlines()):\n",
        "                # map tags to their indices\n",
        "                self.tag_map[t] = i\n",
        "\n",
        "        # adding dataset parameters to param\n",
        "        params.update(json_path)\n",
        "\n",
        "    def load_sentences_labels(self, sentences_file, labels_file, d):\n",
        "        \"\"\"\n",
        "        Loads sentences and labels from their corresponding files. Maps tokens and tags to their indices and stores\n",
        "        them in the provided dict d.\n",
        "        Args:\n",
        "                sentences_file: (string) file with sentences with tokens space-separated\n",
        "                labels_file: (string) file with NER tags for the sentences in labels_file\n",
        "                d: (dict) a dictionary in which the loaded data is stored\n",
        "        \"\"\"\n",
        "\n",
        "        sentences = []\n",
        "        labels = []\n",
        "\n",
        "        with open(sentences_file) as f:\n",
        "            for sentence in f.read().splitlines():\n",
        "                s = [self.vocab[token] if token in self.vocab\n",
        "                     else self.unk_ind\n",
        "                     for token in sentence.split(' ')]\n",
        "                sentences.append(s)\n",
        "\n",
        "        with open(labels_file) as f:\n",
        "            for sentence in f.read().splitlines():\n",
        "                l = [self.tag_map[label] for label in sentence.split(' ')]\n",
        "                labels.append(l)\n",
        "\n",
        "        # ensure there is a tag for each token\n",
        "        assert len(labels) == len(sentences)\n",
        "        for i in range(len(labels)):\n",
        "            assert len(labels[i]) == len(sentences[i])\n",
        "\n",
        "        # storing sentences and labels in a dict\n",
        "        d['data'] = sentences\n",
        "        d['labels'] = labels\n",
        "        d['size'] = len(sentences)\n",
        "\n",
        "    def load_data(self, types, data_dir):\n",
        "        \"\"\"Loads data for each type in types from data_dir\"\"\"\n",
        "\n",
        "        data = {}\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            if split in types:\n",
        "                sentences_file = os.path.join(data_dir, split, 'sentences.txt')\n",
        "                labels_file = os.path.join(data_dir, split, 'labels.txt')\n",
        "                data[split] = {}\n",
        "                self.load_sentences_labels(\n",
        "                    sentences_file, labels_file, data[split])\n",
        "\n",
        "        return data\n",
        "\n",
        "    def data_iterator(self, data, params, shuffle=False):\n",
        "        \"\"\"\n",
        "        Returns a generator that yields batches of data with labels. Batch size is params.batch_size. Expires after one\n",
        "        pass over the data.\n",
        "        Args:\n",
        "            data: (dict) contains data which has keys 'data', 'labels' and 'size'\n",
        "            params: (Params) hyperparameters of the training process.\n",
        "            shuffle: (bool) whether the data should be shuffled\n",
        "        Yields:\n",
        "            batch_data: (Variable) dimension batch_size x seq_len with the sentence data\n",
        "            batch_labels: (Variable) dimension batch_size x seq_len with the corresponding labels\n",
        "        \"\"\"\n",
        "\n",
        "        # make a list that decides the order in which we go over the data- this avoids explicit shuffling of data\n",
        "        order = list(range(data['size']))\n",
        "        if shuffle:\n",
        "            random.seed(230)\n",
        "            random.shuffle(order)\n",
        "\n",
        "        # one pass over data\n",
        "        for i in range(data['size'] + 1 // params.batch_size):\n",
        "            # fetch sentences and tags\n",
        "            batch_sentences = [data['data'][idx]\n",
        "                               for idx in order[i * params.batch_size:(i + 1) * params.batch_size]]\n",
        "            batch_tags = [data['labels'][idx] for idx in order[i *\n",
        "                                                               params.batch_size:(i + 1) * params.batch_size]]\n",
        "\n",
        "            # compute length of longest sentence in the batch\n",
        "            batch_max_len = max([len(s) for s in batch_sentences])\n",
        "\n",
        "            # prepare a numpy array with the data, initialising the data with pad_ind and all labels with -1\n",
        "            # initialising labels to -1 differentiates tokens with tags from PADding tokens\n",
        "            batch_data = self.pad_ind * \\\n",
        "                np.ones((len(batch_sentences), batch_max_len))\n",
        "            batch_labels = -1 * np.ones((len(batch_sentences), batch_max_len))\n",
        "\n",
        "            # copy the data to the numpy array\n",
        "            for j in range(len(batch_sentences)):\n",
        "                cur_len = len(batch_sentences[j])\n",
        "                batch_data[j][:cur_len] = batch_sentences[j]\n",
        "                batch_labels[j][:cur_len] = batch_tags[j]\n",
        "\n",
        "            batch_data, batch_labels = torch.LongTensor(\n",
        "                batch_data), torch.LongTensor(batch_labels)\n",
        "\n",
        "            # shift tensors to GPU if available\n",
        "            if params.cuda:\n",
        "                batch_data, batch_labels = batch_data.cuda(), batch_labels.cuda()\n",
        "\n",
        "            # convert them to Variables to record operations in the computational graph\n",
        "            batch_data, batch_labels = Variable(\n",
        "                batch_data), Variable(batch_labels)\n",
        "\n",
        "            yield batch_data, batch_labels"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTzBLXPp3_Nh"
      },
      "source": [
        "### 5) Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOUvNwjX3_Ni"
      },
      "source": [
        "def train(model, optimizer, loss_fn, data_iterator, metrics, params, num_steps):\n",
        "    \"\"\"Train the model on `num_steps` batches\"\"\"\n",
        "\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # summary for current training loop and a running average object for loss\n",
        "    summ = []\n",
        "    loss_avg = utils.RunningAverage()\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    t = trange(num_steps)\n",
        "    for i in t:\n",
        "        train_batch, labels_batch = next(data_iterator)\n",
        "\n",
        "        output_batch = model(train_batch)\n",
        "        loss = loss_fn(output_batch, labels_batch)\n",
        "\n",
        "        optimizer.zero_grad()  # clear gradients\n",
        "        loss.backward()         # compute gradients wrt loss\n",
        "        optimizer.step()        # update gradients\n",
        "\n",
        "        if i % params.save_summary_steps == 0:\n",
        "            # convert tensor data to numpy\n",
        "            output_batch = output_batch.data.cpu().numpy()\n",
        "            labels_batch = labels_batch.data.cpu().numpy()\n",
        "\n",
        "            # compute all metrics on this batch\n",
        "            summary_batch = {metric: metrics[metric](\n",
        "                output_batch, labels_batch) for metric in metrics}\n",
        "            summary_batch['loss'] = loss.item()\n",
        "            summ.append(summary_batch)\n",
        "\n",
        "        # update the average loss\n",
        "        loss_avg.update(loss.item())\n",
        "        t.set_postfix(loss='{:05.3f}'.format(loss_avg()))\n",
        "\n",
        "        # compute mean of all metrics in summary\n",
        "        metrics_mean = {metric: np.mean(\n",
        "            [x[metric] for x in summ]) for metric in summ[0]}\n",
        "        metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
        "                                    for k, v in metrics_mean.items())\n",
        "        logging.info('- Train metrics: ' + metrics_string)\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDzF7LkR3_Nm"
      },
      "source": [
        "def train_and_evaluate(model, train_data, val_data, optimizer, loss_fn, metrics, params, model_dir, restore_file=None):\n",
        "    if restore_file is not None:\n",
        "        restore_path = os.path.join(\n",
        "            model_dir, restore_file + '.pth.tar')\n",
        "        logging.info('Restoring parameters from {}'.format(restore_path))\n",
        "        utils.load_checkpoint(restore_path, model, optimizer)\n",
        "\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(params.num_epochs):\n",
        "        # Run one epoch\n",
        "        logging.info('Epoch {}/{}'.format(epoch + 1, params.num_epochs))\n",
        "\n",
        "        # Compute number of batches in one epoch\n",
        "        num_steps = (params.train_size + 1) // params.batch_size\n",
        "        train_data_iterator = data_loader.data_iterator(\n",
        "            train_data, params, shuffle=True)\n",
        "        train(model, optimizer, loss_fn, train_data_iterator,\n",
        "              metrics, params, num_steps)\n",
        "\n",
        "        # Evaluate for one epoch on validation set\n",
        "        num_steps = (params.val_size + 1) // params.batch_size\n",
        "        val_data_iterator = data_loader.data_iterator(\n",
        "            val_data, params, shuffle=False)\n",
        "        val_metrics = evaluate(\n",
        "            model, loss_fn, val_data_iterator, metrics, params, num_steps)\n",
        "\n",
        "        val_acc = val_metrics['accuracy']\n",
        "        is_best = val_acc >= best_val_acc\n",
        "\n",
        "    \n",
        "        # If best_eval, best_save_path\n",
        "        if is_best:\n",
        "            logging.info('- Found new best accuracy')\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "            # Save best val metrics in a json file in the model directory\n",
        "            best_json_path = os.path.join(\n",
        "                model_dir, 'metrics_val_best_weights.json')\n",
        "            utils.save_dict_to_json(val_metrics, best_json_path)\n",
        "\n",
        "        # Save latest val metrics in a json file in the model directory\n",
        "        last_json_path = os.path.join(\n",
        "            model_dir, 'metrics_val_last_weights.json')\n",
        "        utils.save_dict_to_json(val_metrics, last_json_path)\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FmPqAba3_Nq"
      },
      "source": [
        "json_path = os.path.join(\"./\", 'params.json')\n",
        "assert os.path.isfile(\n",
        "    json_path), \"No json config file found at {}\".format(json_path)\n",
        "params = utils.Params(json_path)\n",
        "\n",
        "params.cuda = torch.cuda.is_available()"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m8343Ie3_Nt"
      },
      "source": [
        "torch.manual_seed(230)\n",
        "\n",
        "if params.cuda:\n",
        "    torch.cuda.manual_seed(230)\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX0Xvi1z3_Nw"
      },
      "source": [
        "# Set the logger\n",
        "#utils.set_logger(os.path.join(\"./logs\", 'train.log'))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDuXL6Md3_N0"
      },
      "source": [
        "# Create the input data pipeline\n",
        "logging.info(\"Loading the datasets...\")"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR5P6MA83_N5"
      },
      "source": [
        "# load data\n",
        "data_loader = DataLoader('/content/drive/My Drive/Colab Notebooks/datasets and models/data/', params)\n",
        "data = data_loader.load_data(['train', 'val'], '/content/drive/My Drive/Colab Notebooks/datasets and models/data/')\n",
        "train_data = data['train']\n",
        "val_data = data['val']"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utl6ZdzT3_N8"
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cstAEK03_OA"
      },
      "source": [
        "# specify the train and val dataset sizes\n",
        "params.train_size = train_data['size']\n",
        "params.val_size = val_data['size']\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE3SedNL3_OD"
      },
      "source": [
        "logging.info('- done.')"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "471TPGM13_OG"
      },
      "source": [
        "# Define the model and optimizer\n",
        "model = Model(params).cuda() if params.cuda else Model(params)\n",
        "optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m0yAl3Y3_OL",
        "outputId": "fa0cfeb2-ee1b-4ac8-fc9e-a6f132da1ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(model)\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (embedding): Embedding(35180, 50)\n",
            "  (lstm): LSTM(50, 50, batch_first=True)\n",
            "  (fc): Linear(in_features=50, out_features=17, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O88OksNZ3_OP",
        "outputId": "958be992-2bc4-4752-dfa2-6ccaa5b40ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        " train_and_evaluate(model, train_data, val_data, optimizer,\n",
        "                       loss_fn, metrics, params, \"./\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6714/6714 [00:50<00:00, 133.01it/s, loss=0.353]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-01606e32a2f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_and_evaluate(model, train_data, val_data, optimizer,\n\u001b[0;32m----> 2\u001b[0;31m                       loss_fn, metrics, params, \"./\")\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-b0dffec5713a>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_data, val_data, optimizer, loss_fn, metrics, params, model_dir, restore_file)\u001b[0m\n\u001b[1;32m     39\u001b[0m             best_json_path = os.path.join(\n\u001b[1;32m     40\u001b[0m                 model_dir, 'metrics_val_best_weights.json')\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dict_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_json_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Save latest val metrics in a json file in the model directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'save_dict_to_json'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygBAfsEF3_OW"
      },
      "source": [
        "#### 6) Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR9YMEsZ3_OX"
      },
      "source": [
        "def evaluate(model, loss_fn, data_iterator, metrics, params, num_steps):\n",
        "    \"\"\"Evaluate the model on 'num_steps' batches\"\"\"\n",
        "\n",
        "    model.eval()    # set model to evaluation mode\n",
        "    summ = []       # summary for current eval loop\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        data_batch, labels_batch = next(data_iterator)\n",
        "\n",
        "        output_batch = model(data_batch)\n",
        "        loss = loss_fn(output_batch, labels_batch)\n",
        "\n",
        "        output_batch = output_batch.data.cpu().numpy()\n",
        "        labels_batch = labels_batch.data.cpu().numpy()\n",
        "\n",
        "        summary_batch = {metric: metrics[metric](\n",
        "            output_batch, labels_batch) for metric in metrics}\n",
        "        summary_batch['loss'] = loss.item()\n",
        "        summ.append(summary_batch)\n",
        "\n",
        "    # compute mean of all metrics in summary\n",
        "    metrics_mean = {metric: np.mean([x[metric]\n",
        "                                     for x in summ]) for metric in summ[0]}\n",
        "    metrics_string = \" ; \".join(\"{}: {:05.3f}\".format(k, v)\n",
        "                                for k, v in metrics_mean.items())\n",
        "    logging.info('- Eval metrics: ' + metrics_string)\n",
        "    return metrics_mean"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAJLvf5N3_Oa"
      },
      "source": [
        "# Get the logger\n",
        "#utils.set_logger(os.path.join(\"./logs\", 'evaluate.log'))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLUSt8Ma3_Oc"
      },
      "source": [
        "# load data\n",
        "data_loader = DataLoader('/content/drive/My Drive/Colab Notebooks/datasets and models/data/', params)\n",
        "data = data_loader.load_data(['val'], '/content/drive/My Drive/Colab Notebooks/datasets and models/data/')\n",
        "test_data = data['val']"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSL9BG4a3_Og"
      },
      "source": [
        "# specify the test set size\n",
        "params.test_size = test_data['size']\n",
        "test_data_iterator = data_loader.data_iterator(test_data, params)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P56P5bOt3_Ol",
        "outputId": "e2b7faf3-703c-4e4f-9603-9b284115b5ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_data_iterator)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object DataLoader.data_iterator at 0x7f57585f4bf8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUky0xFz3_Op",
        "outputId": "0bcf9c4a-88e9-469a-d5fc-bfe91967157c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "print(next(test_data_iterator)[0])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1020,    68,  5092,    50,     9, 29845,  1677, 18327,  1033,     9,\n",
            "          4452,    13,   522, 29846,    45, 10314,   223,  6582,    21, 35178,\n",
            "         35178, 35178],\n",
            "        [ 6607, 10092,    31,    45,  2112,    80,     9,   580,   581,   855,\n",
            "         20336,   857,    63,   363,    93,  2822,   347,  6657, 10314,    18,\n",
            "          6599,    21],\n",
            "        [ 1641,   151,   817,   120,  1354,  1790,  1053,  1054,   864,    21,\n",
            "         35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178, 35178,\n",
            "         35178, 35178],\n",
            "        [ 1615,  1384,   125,   172,   107,    45,  7127,  1566,    18,  1724,\n",
            "           337,  1002,   322,   116,    18,     9,  1065,  1052,    21, 35178,\n",
            "         35178, 35178],\n",
            "        [ 2798,    93,  5154,   125,   126,  1053,  1054,    24,   134, 14349,\n",
            "          1559,    63,   882,  1466,     7,    45,   884,   107,    21, 35178,\n",
            "         35178, 35178]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl3uAsmU3_Ot",
        "outputId": "fac58537-2dc2-4acd-80c4-73c0c04a67eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(next(test_data_iterator)[1])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  0,  0,  0,  0,  0,  1,  0, -1],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  7,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0,  1,  0,  0,  0,  0, -1, -1, -1],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -1, -1,\n",
            "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
            "        [ 5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  1,  0,  1,  4,  0,\n",
            "          0,  0,  0,  1,  0,  1,  0,  0,  0,  0],\n",
            "        [ 0,  0,  0,  0,  0,  0,  0,  0,  7, 12,  0, -1, -1, -1, -1, -1, -1, -1,\n",
            "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raoNHyzd3_Ov"
      },
      "source": [
        "torch.save(model.state_dict(), \"NER-Epoch100.pth\")"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Y-tCpo3_Oy"
      },
      "source": [
        "pred = model(next(test_data_iterator)[0])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqPrG-AV8ZaZ",
        "outputId": "79a9d075-4ba4-4d51-df80-7f086791fc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-4.9870e-02, -5.5602e+00, -7.4069e+00,  ..., -8.0736e+00,\n",
            "         -8.2532e+00, -9.4013e+00],\n",
            "        [-3.0100e-03, -8.1961e+00, -1.1800e+01,  ..., -1.1182e+01,\n",
            "         -1.0437e+01, -1.3208e+01],\n",
            "        [-3.6463e+00, -8.0811e-02, -5.0329e+00,  ..., -8.5043e+00,\n",
            "         -1.0360e+01, -1.1429e+01],\n",
            "        ...,\n",
            "        [-5.1000e-01, -5.6407e+00, -5.2204e+00,  ..., -7.3921e+00,\n",
            "         -7.7477e+00, -8.5167e+00],\n",
            "        [-5.9379e-01, -5.7015e+00, -5.1903e+00,  ..., -7.4786e+00,\n",
            "         -7.8078e+00, -8.5684e+00],\n",
            "        [-6.7590e-01, -5.7780e+00, -5.1727e+00,  ..., -7.5779e+00,\n",
            "         -7.8852e+00, -8.6467e+00]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xs4wcjI8blm",
        "outputId": "b7a70c6a-eacc-4d19-e193-3344d93a7c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(pred.argmax())"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2278, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-vQUPv9-ZXB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}